# -*- coding: utf-8 -*-
"""InceptionV3_Project

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1NGrMSpgcHYzDUrkY-5-HrnECKUECY5Xm

# Inception V3

# AI Fundamental Project: Inception V3

 #### **프로젝트 목적: Inception V3를 활용한 음식 카데고리 분류**

참고사항
*   Python 3.10 Library
*   Tensorflow 2.15.0
*   T4 GPU Hardware
*   Dataset: iFood - 2019 at FGVC6

## Inception V3 배경

논문: Rethinking the Inception Architecture for Computer Vision [논문 링크](https://arxiv.org/abs/1512.00567)

#### Inception V3의 특장점:

*   더 적은 파라미터 수로 깊은 층을 만들 수 있는 구조. (42-layer 신경망)
*   앙상블 기법을 활용한 top-1 17.2% error, top-5 3.58% error를 달성 (ILSVR 2012 dataset 기준) -> VGGNet와 비슷한 연상량
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt

#라이브러리 불러오기
from keras.applications.inception_v3 import InceptionV3
from keras.preprocessing import image
from keras.models import Model
from keras.applications.inception_v3 import preprocess_input, decode_predictions

#이미 학습된 모델: Pre-trained model 불러오기
model = InceptionV3(weights = 'imagenet', include_top = True)

for i in range(1,5):
  img_path = f'./test_img/cat{i}.jpg'
  img = image.load_img(img_path, target_size=(299, 299))
  #이미지 형식에 맞게 수정
  x = image.img_to_array(img)
  x = np.expand_dims(x, axis=0)
  #이미지 전처리
  x = preprocess_input(x)
  #예측
  preds = model.predict(x)
  result = decode_predictions(preds, top=5)
  print(result)
  print('Predicted:', result)

  #이미지 표시
  plt.imshow(image.load_img(img_path))
  plt.show()

  #어떤 것을 검출했는지 확인
  for ii in range(5):
    print("Top[{}] => {}, {}".format(
        ii+1,
        result[0][ii][1],
        result[0][ii][2]))

from google.colab import drive
drive.mount('/content/drive')

"""# 환경설정"""

!pwd

# Commented out IPython magic to ensure Python compatibility.
# %cd /content/drive/MyDrive/dataset/

!ls

"""# 2. 라이브러리 및 데이터 처리

## 데이터 분류 및 정리

train,val,test 디렉터리를 만들고 11만개의 데이터를 정리한다.

이후 train 데이터 전처리를 위해 음식 이름별로 또 한번 분류해서 디렉터리를 만들어주면 나중에 편리할 것 같아 수행해 준다.
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt

import tensorflow as tf
from keras.preprocessing.image import ImageDataGenerator
from keras.applications.inception_v3 import InceptionV3
from keras.models import Model
from keras.layers import Dense,Dropout, BatchNormalization
from keras.optimizers import Adam
from keras.callbacks import ModelCheckpoint

# 학습데이터 Train 경로
data_dir = '/content/drive/MyDrive/dataset/food10/'
data = tf.keras.preprocessing.image_dataset_from_directory(data_dir)

#데이터 인공지능이 학습 가능한 형태로 변환

datagen = ImageDataGenerator(
    rescale=1./255,
    rotation_range=40,
    width_shift_range=0.2,
    height_shift_range=0.2,
    shear_range=0.2,
    zoom_range=0.2,
    horizontal_flip=True,
    validation_split=0.2)

width = 228
height = 228
batch_size = 32
channel = 3
image_shape = (width, height, channel)
image_size = (width, height)

#데이터 변환
train_data = datagen.flow_from_directory(
    data_dir,
    target_size=image_size,
    batch_size=batch_size,
    subset='training')

train_data.class_indices

val_data = datagen.flow_from_directory(
    data_dir,
    target_size=image_size,
    batch_size=batch_size,
    subset='validation',
    shuffle = True)
#

#클래스 명칭설정

num_classes = len(data.class_names)
data.class_names

#학습할 이미지에 대한 Preview
# 15 X 15 사이즈 이미지에서, 각 칸 마다 Image를 하나 선택해서 불러오기
def show_image(data):
    plt.figure(figsize=(15,15))
    for images, labels in data.take(1):
        for i in range(9):
            ax = plt.subplot(3, 3, i + 1)
            plt.imshow(images[i].numpy().astype("uint8"))
            plt.title(data.class_names[labels[i]])
            plt.axis("off")

show_image(data)

"""# 3. 인공지능 알고리즘 설계"""

pre_model = InceptionV3(
    weights = 'imagenet',
    include_top = False,
    input_shape = image_shape,
    pooling = 'avg')

pre_model.summary()

#모델 설계
#Convolution 맨 마지막에 fully connected layers에서 어떻게 처리할지 정해준다.
x = pre_model.output
x = BatchNormalization(axis = -1, momentum = 0.99, epsilon = 0.001)(x) #성능이 좋았던 paramters, hyperparameter 튜닝으로 학습 성능 증가한 parameter.
x = Dropout(0.2)(x)
x = Dense(1024, activation = 'relu')(x)
x = Dropout(0.2)(x)
predictions = Dense(num_classes, activation = 'softmax')(x)

#모델 컴파일

model = Model(inputs = pre_model.input, outputs = predictions)
model.compile(optimizer = Adam(learning_rate = 0.0001),
              loss = 'categorical_crossentropy',
              metrics = ['accuracy'])

model.summary()

#단위한 학습량을 변수로 조정
STEP_SIZE_TRAIN = train_data.n // train_data.batch_size
STEP_SIZE_VALID = val_data.n // val_data.batch_size
STEP_SIZE_TRAIN, STEP_SIZE_VALID

#CallBack 처리
from keras.callbacks import ModelCheckpoint

EPOCHS = 10 # 유료로 사용할 수 있게 됬을 때, 50으로 변경하면 좋을 것 같다.
filename = '/content/drive/MyDrive/train/ipv3-epoch_{epoch}.h5'
checkpoint = ModelCheckpoint(filename, monitor = 'val_loss', verbose = 1, save_best_only = True, mode = 'auto')

history = model.fit(
    train_data,
    steps_per_epoch = STEP_SIZE_TRAIN,
    validation_data = val_data,
    validation_steps = STEP_SIZE_VALID,
    epochs = EPOCHS,
    callbacks = [checkpoint])

